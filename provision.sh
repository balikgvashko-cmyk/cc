#!/bin/bash

source /venv/main/bin/activate
COMFYUI_DIR=${WORKSPACE}/ComfyUI

APT_PACKAGES=(
)

PIP_PACKAGES=(
)

NODES=(
)

WORKFLOWS=(
)

CHECKPOINT_MODELS=(
)

UNET_MODELS=(
)

LORA_MODELS=(
)

VAE_MODELS=(
)

ESRGAN_MODELS=(
)

CONTROLNET_MODELS=(
)

###############################################
### QWEN IMAGE EDIT 2511 â€” FULL DIFFUSERS MODEL
###############################################

QWEN2511_DIR="${COMFYUI_DIR}/models/qwen_image_edit_2511"

function provisioning_qwen_image_edit_2511() {
    echo "Setting up Qwen-Image-Edit-2511 model..."

    mkdir -p "${QWEN2511_DIR}/unet"
    mkdir -p "${QWEN2511_DIR}/vae"
    mkdir -p "${QWEN2511_DIR}/text_encoder"
    mkdir -p "${QWEN2511_DIR}/tokenizer"
    mkdir -p "${QWEN2511_DIR}/scheduler"
    mkdir -p "${QWEN2511_DIR}/feature_extractor"

    # model_index.json
    provisioning_download \
        "https://huggingface.co/Qwen/Qwen-Image-Edit-2511/resolve/main/model_index.json" \
        "${QWEN2511_DIR}"

    ######## UNET ########
    provisioning_download \
        "https://huggingface.co/Qwen/Qwen-Image-Edit-2511/resolve/main/unet/config.json" \
        "${QWEN2511_DIR}/unet"

    provisioning_download \
        "https://huggingface.co/Qwen/Qwen-Image-Edit-2511/resolve/main/unet/diffusion_pytorch_model.safetensors" \
        "${QWEN2511_DIR}/unet"

    ######## VAE ########
    provisioning_download \
        "https://huggingface.co/Qwen/Qwen-Image-Edit-2511/resolve/main/vae/config.json" \
        "${QWEN2511_DIR}/vae"

    provisioning_download \
        "https://huggingface.co/Qwen/Qwen-Image-Edit-2511/resolve/main/vae/diffusion_pytorch_model.safetensors" \
        "${QWEN2511_DIR}/vae"

    ######## TEXT ENCODER ########
    provisioning_download \
        "https://huggingface.co/Qwen/Qwen-Image-Edit-2511/resolve/main/text_encoder/config.json" \
        "${QWEN2511_DIR}/text_encoder"

    provisioning_download \
        "https://huggingface.co/Qwen/Qwen-Image-Edit-2511/resolve/main/text_encoder/model.safetensors" \
        "${QWEN2511_DIR}/text_encoder"

    ######## TOKENIZER ########
    provisioning_download \
        "https://huggingface.co/Qwen/Qwen-Image-Edit-2511/resolve/main/tokenizer/tokenizer.json" \
        "${QWEN2511_DIR}/tokenizer"

    provisioning_download \
        "https://huggingface.co/Qwen/Qwen-Image-Edit-2511/resolve/main/tokenizer/tokenizer_config.json" \
        "${QWEN2511_DIR}/tokenizer"

    provisioning_download \
        "https://huggingface.co/Qwen/Qwen-Image-Edit-2511/resolve/main/tokenizer/vocab.json" \
        "${QWEN2511_DIR}/tokenizer"

    provisioning_download \
        "https://huggingface.co/Qwen/Qwen-Image-Edit-2511/resolve/main/tokenizer/merges.txt" \
        "${QWEN2511_DIR}/tokenizer"

    ######## SCHEDULER ########
    provisioning_download \
        "https://huggingface.co/Qwen/Qwen-Image-Edit-2511/resolve/main/scheduler/scheduler_config.json" \
        "${QWEN2511_DIR}/scheduler"

    ######## FEATURE EXTRACTOR ########
    provisioning_download \
        "https://huggingface.co/Qwen/Qwen-Image-Edit-2511/resolve/main/feature_extractor/preprocessor_config.json" \
        "${QWEN2511_DIR}/feature_extractor"

    echo "Qwen-Image-Edit-2511 provisioning complete."
}

### DO NOT EDIT BELOW HERE UNLESS YOU KNOW WHAT YOU ARE DOING ###

function provisioning_start() {
    provisioning_print_header
    provisioning_get_apt_packages
    provisioning_get_nodes
    provisioning_get_pip_packages

    provisioning_get_files "${COMFYUI_DIR}/models/checkpoints" "${CHECKPOINT_MODELS[@]}"
    provisioning_get_files "${COMFYUI_DIR}/models/unet" "${UNET_MODELS[@]}"
    provisioning_get_files "${COMFYUI_DIR}/models/lora" "${LORA_MODELS[@]}"
    provisioning_get_files "${COMFYUI_DIR}/models/controlnet" "${CONTROLNET_MODELS[@]}"
    provisioning_get_files "${COMFYUI_DIR}/models/vae" "${VAE_MODELS[@]}"
    provisioning_get_files "${COMFYUI_DIR}/models/esrgan" "${ESRGAN_MODELS[@]}"

    # Qwen Image Edit 2511
    provisioning_qwen_image_edit_2511

    provisioning_print_end
}

function provisioning_get_apt_packages() {
    if [[ -n $APT_PACKAGES ]]; then
            sudo $APT_INSTALL ${APT_PACKAGES[@]}
    fi
}

function provisioning_get_pip_packages() {
    if [[ -n $PIP_PACKAGES ]]; then
            pip install --no-cache-dir ${PIP_PACKAGES[@]}
    fi
}

function provisioning_get_nodes() {
    for repo in "${NODES[@]}"; do
        dir="${repo##*/}"
        path="${COMFYUI_DIR}custom_nodes/${dir}"
        requirements="${path}/requirements.txt"
        if [[ -d $path ]]; then
            if [[ ${AUTO_UPDATE,,} != "false" ]]; then
                printf "Updating node: %s...\n" "${repo}"
                ( cd "$path" && git pull )
                if [[ -e $requirements ]]; then
                   pip install --no-cache-dir -r "$requirements"
                fi
            fi
        else
            printf "Downloading node: %s...\n" "${repo}"
            git clone "${repo}" "${path}" --recursive
            if [[ -e $requirements ]]; then
                pip install --no-cache-dir -r "${requirements}"
            fi
        fi
    done
}

function provisioning_get_files() {
    if [[ -z $2 ]]; then return 1; fi
    
    dir="$1"
    mkdir -p "$dir"
    shift
    arr=("$@")
    printf "Downloading %s model(s) to %s...\n" "${#arr[@]}" "$dir"
    for url in "${arr[@]}"; do
        printf "Downloading: %s\n" "${url}"
        provisioning_download "${url}" "${dir}"
        printf "\n"
    done
}

function provisioning_print_header() {
    printf "\n##############################################\n#                                            #\n#          Provisioning container            #\n#                                            #\n#         This will take some time           #\n#                                            #\n# Your container will be ready on completion #\n#                                            #\n##############################################\n\n"
}

function provisioning_print_end() {
    printf "\nProvisioning complete:  Application will start now\n\n"
}

function provisioning_has_valid_hf_token() {
    [[ -n "$HF_TOKEN" ]] || return 1
    url="https://huggingface.co/api/whoami-v2"

    response=$(curl -o /dev/null -s -w "%{http_code}" -X GET "$url" \
        -H "Authorization: Bearer $HF_TOKEN" \
        -H "Content-Type: application/json")

    if [ "$response" -eq 200 ]; then
        return 0
    else
        return 1
    fi
}

function provisioning_has_valid_civitai_token() {
    [[ -n "$CIVITAI_TOKEN" ]] || return 1
    url="https://civitai.com/api/v1/models?hidden=1&limit=1"

    response=$(curl -o /dev/null -s -w "%{http_code}" -X GET "$url" \
        -H "Authorization: Bearer $CIVITAI_TOKEN" \
        -H "Content-Type: application/json")

    if [ "$response" -eq 200 ]; then
        return 0
    else
        return 1
    fi
}

function provisioning_download() {
    if [[ -n $HF_TOKEN && $1 =~ ^https://([a-zA-Z0-9_-]+\.)?huggingface\.co(/|$|\?) ]]; then
        auth_token="$HF_TOKEN"
    elif [[ -n $CIVITAI_TOKEN && $1 =~ ^https://([a-zA-Z0-9_-]+\.)?civitai\.com(/|$|\?) ]]; then
        auth_token="$CIVITAI_TOKEN"
    fi
    if [[ -n $auth_token ]];then
        wget --header="Authorization: Bearer $auth_token" -qnc --content-disposition --show-progress -e dotbytes="${3:-4M}" -P "$2" "$1"
    else
        wget -qnc --content-disposition --show-progress -e dotbytes="${3:-4M}" -P "$2" "$1"
    fi
}

if [[ ! -f /.noprovisioning ]]; then
    provisioning_start
fi
